{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBx8nOgHjVxN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpJRBV7tjVxR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWdBqDiMjVxS"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = 'D:/Retina data/train'\n",
        "valid_path = 'D:/Retina data/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02gCdUoIjVxT"
      },
      "outputs": [],
      "source": [
        "vgg19 = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6vznfyejVxT"
      },
      "outputs": [],
      "source": [
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9lkXT5ljVxT"
      },
      "outputs": [],
      "source": [
        "x = Flatten()(vgg19.output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90Ccc6znjVxU"
      },
      "outputs": [],
      "source": [
        "prediction = Dense(4, activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=vgg19.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEX7eJFUjVxV",
        "outputId": "b7cd6ed8-758e-4b30-c5a6-fde3ec14f656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 100356    \n",
            "=================================================================\n",
            "Total params: 20,124,740\n",
            "Trainable params: 100,356\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7ODVfP4jVxW"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GHG1N03jVxX"
      },
      "outputs": [],
      "source": [
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ATV-y2ljVxX",
        "outputId": "1e391ca3-fd8e-425f-fbd9-67a9725979de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 63652 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory('D:/Retina data/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 40,\n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RRwagKbjVxY",
        "outputId": "04ae20c0-2e9a-413e-bfdd-b3aa7f64f729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 968 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "test_set = test_datagen.flow_from_directory('D:/Retina data/test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 40,\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gvc7hkPNjVxY",
        "outputId": "29b22588-c88f-45bb-e416-0c2e096b2854"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E:\\New folder (2)\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1592/1592 [==============================] - 1711s 1s/step - loss: 0.5231 - accuracy: 0.8088 - val_loss: 0.2382 - val_accuracy: 0.9225\n",
            "Epoch 2/30\n",
            "1592/1592 [==============================] - 662s 416ms/step - loss: 0.4329 - accuracy: 0.8493 - val_loss: 0.2648 - val_accuracy: 0.9060\n",
            "Epoch 3/30\n",
            "1592/1592 [==============================] - 619s 389ms/step - loss: 0.3981 - accuracy: 0.8635 - val_loss: 0.1740 - val_accuracy: 0.9390\n",
            "Epoch 4/30\n",
            "1592/1592 [==============================] - 615s 387ms/step - loss: 0.3886 - accuracy: 0.8671 - val_loss: 0.1638 - val_accuracy: 0.9411\n",
            "Epoch 5/30\n",
            "1592/1592 [==============================] - 622s 391ms/step - loss: 0.3925 - accuracy: 0.8690 - val_loss: 0.2097 - val_accuracy: 0.9308\n",
            "Epoch 6/30\n",
            "1592/1592 [==============================] - 616s 387ms/step - loss: 0.3855 - accuracy: 0.8727 - val_loss: 0.1271 - val_accuracy: 0.9566\n",
            "Epoch 7/30\n",
            "1592/1592 [==============================] - 616s 387ms/step - loss: 0.3589 - accuracy: 0.8799 - val_loss: 0.1068 - val_accuracy: 0.9566\n",
            "Epoch 8/30\n",
            "1592/1592 [==============================] - 621s 390ms/step - loss: 0.3666 - accuracy: 0.8783 - val_loss: 0.1959 - val_accuracy: 0.9246\n",
            "Epoch 9/30\n",
            "1592/1592 [==============================] - 615s 386ms/step - loss: 0.3503 - accuracy: 0.8827 - val_loss: 0.1333 - val_accuracy: 0.9494\n",
            "Epoch 10/30\n",
            "1592/1592 [==============================] - 616s 387ms/step - loss: 0.3526 - accuracy: 0.8829 - val_loss: 0.1284 - val_accuracy: 0.9514\n",
            "Epoch 11/30\n",
            "1592/1592 [==============================] - 621s 390ms/step - loss: 0.3469 - accuracy: 0.8853 - val_loss: 0.1235 - val_accuracy: 0.9576\n",
            "Epoch 12/30\n",
            "1592/1592 [==============================] - 616s 387ms/step - loss: 0.3501 - accuracy: 0.8853 - val_loss: 0.1330 - val_accuracy: 0.9535\n",
            "Epoch 13/30\n",
            "1592/1592 [==============================] - 616s 387ms/step - loss: 0.3466 - accuracy: 0.8872 - val_loss: 0.1264 - val_accuracy: 0.9576\n",
            "Epoch 14/30\n",
            "1592/1592 [==============================] - 621s 390ms/step - loss: 0.3322 - accuracy: 0.8893 - val_loss: 0.1061 - val_accuracy: 0.9628\n",
            "Epoch 15/30\n",
            "1592/1592 [==============================] - 616s 387ms/step - loss: 0.3325 - accuracy: 0.8916 - val_loss: 0.3220 - val_accuracy: 0.8853\n",
            "Epoch 16/30\n",
            "1592/1592 [==============================] - 617s 388ms/step - loss: 0.3393 - accuracy: 0.8887 - val_loss: 0.1400 - val_accuracy: 0.9504\n",
            "Epoch 17/30\n",
            "1592/1592 [==============================] - 607s 381ms/step - loss: 0.3401 - accuracy: 0.8893 - val_loss: 0.1660 - val_accuracy: 0.9411\n",
            "Epoch 18/30\n",
            "1592/1592 [==============================] - 602s 378ms/step - loss: 0.3301 - accuracy: 0.8934 - val_loss: 0.1601 - val_accuracy: 0.9390\n",
            "Epoch 19/30\n",
            "1592/1592 [==============================] - 603s 379ms/step - loss: 0.3357 - accuracy: 0.8917 - val_loss: 0.1472 - val_accuracy: 0.9535\n",
            "Epoch 20/30\n",
            "1592/1592 [==============================] - 605s 380ms/step - loss: 0.3155 - accuracy: 0.8969 - val_loss: 0.0966 - val_accuracy: 0.9618\n",
            "Epoch 21/30\n",
            "1592/1592 [==============================] - 638s 401ms/step - loss: 0.3326 - accuracy: 0.8915 - val_loss: 0.0910 - val_accuracy: 0.9711\n",
            "Epoch 22/30\n",
            "1592/1592 [==============================] - 641s 402ms/step - loss: 0.3181 - accuracy: 0.8959 - val_loss: 0.2150 - val_accuracy: 0.9370\n",
            "Epoch 23/30\n",
            "1592/1592 [==============================] - 640s 402ms/step - loss: 0.3301 - accuracy: 0.8939 - val_loss: 0.1222 - val_accuracy: 0.9576\n",
            "Epoch 24/30\n",
            "1592/1592 [==============================] - 601s 378ms/step - loss: 0.3242 - accuracy: 0.8945 - val_loss: 0.1551 - val_accuracy: 0.9514\n",
            "Epoch 25/30\n",
            "1592/1592 [==============================] - 592s 372ms/step - loss: 0.3202 - accuracy: 0.8962 - val_loss: 0.1557 - val_accuracy: 0.9370\n",
            "Epoch 26/30\n",
            "1592/1592 [==============================] - 595s 374ms/step - loss: 0.3286 - accuracy: 0.8948 - val_loss: 0.1214 - val_accuracy: 0.9576\n",
            "Epoch 27/30\n",
            "1592/1592 [==============================] - 591s 371ms/step - loss: 0.3065 - accuracy: 0.8999 - val_loss: 0.1265 - val_accuracy: 0.9535\n",
            "Epoch 28/30\n",
            "1592/1592 [==============================] - 604s 379ms/step - loss: 0.3244 - accuracy: 0.8965 - val_loss: 0.1175 - val_accuracy: 0.9628\n",
            "Epoch 29/30\n",
            "1592/1592 [==============================] - 606s 381ms/step - loss: 0.3032 - accuracy: 0.9012 - val_loss: 0.1574 - val_accuracy: 0.9401\n",
            "Epoch 30/30\n",
            "1592/1592 [==============================] - 613s 385ms/step - loss: 0.3202 - accuracy: 0.8969 - val_loss: 0.1320 - val_accuracy: 0.9535\n"
          ]
        }
      ],
      "source": [
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=30,\n",
        "  verbose=1,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9ItcKu2jVxZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('eye_E30_ACC89_val95.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKIgEnUxjVxa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_dZ2OwmjVxa"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "15eaa2de2fb53e8ac6d810dfcbd64320756b481602fd63243d3869e73894e1c1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "eyek.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}